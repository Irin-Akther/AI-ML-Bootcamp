# -*- coding: utf-8 -*-
"""Final_Code for insider threat.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1T_qdbnHTZhkkug_2cYYCEeNb7BQ82XGi
"""

!pip install OTXv2
!pip install faker
!pip install torch transformers

import json
import requests
import pandas as pd
import random
from OTXv2 import OTXv2
from faker import Faker
from transformers import BertTokenizer, BertForSequenceClassification, BertModel
from torch.utils.data import DataLoader, Dataset
import torch
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
from sklearn.utils import resample
from sklearn.model_selection import train_test_split
from torch.nn import CrossEntropyLoss

# --- OTX Setup ---
API_KEY = "58b6b1a7fd35c407a9948fadd5a0eecac725668825db03e3d43b668809aaa76c"  # Replace with your OTX API key
otx = OTXv2(API_KEY)

# --- Chat Log Generation ---
faker = Faker()
def generate_chat_logs(num_chats=100):
    logs = []
    for _ in range(num_chats):
        sender = faker.name()
        message = faker.text(max_nb_chars=200)
        logs.append({"sender": sender, "message": message})
    return logs

# Fetch MITRE ATT&CK data
def fetch_mitre_attack_data():
    url = "https://raw.githubusercontent.com/mitre/cti/master/enterprise-attack/enterprise-attack.json"
    response = requests.get(url)
    data = response.json()
    techniques = [obj for obj in data['objects'] if obj.get('type') == 'attack-pattern']
    return techniques

# Enrich chat logs with MITRE ATT&CK techniques
def enrich_with_mitre_attack(chat_logs, techniques):
    for log in chat_logs:
        if random.random() < 0.1:  # Randomly assign techniques
            technique = random.choice(techniques)
            log['technique'] = technique.get('name', 'none')
        else:
            log['technique'] = 'none'
    return chat_logs

mitre_techniques = fetch_mitre_attack_data()
chat_logs = generate_chat_logs(num_chats=100)
enriched_logs = enrich_with_mitre_attack(chat_logs, mitre_techniques)

# Combine chat logs with IOCs
def combine_data_with_iocs(chat_logs, iocs):
    data = []
    for log in chat_logs:
        message = log["message"]
        technique = log.get("technique", "none")
        if random.random() < 0.1 and iocs:  # Assign IOC with probability
            matched_ioc = random.choice(iocs).get('indicator', 'none')
        else:
            matched_ioc = 'none'
        data.append({"message": message, "technique": technique, "ioc": matched_ioc})
    return pd.DataFrame(data)

# Fetch IOCs
try:
    pulses = otx.getall()
    iocs = [{"indicator": indicator} for pulse in pulses for indicator in pulse.get('indicators', [])]
except Exception as e:
    print("Error fetching IOCs:", e)
    iocs = [{"indicator": "none"}]

combined_data = combine_data_with_iocs(enriched_logs, iocs)

# --- Dataset and Dataloader ---
tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')

class ThreatDataset(Dataset):
    def __init__(self, data):
        self.texts = data['message']
        self.labels = data['ioc'].apply(lambda x: 1 if x != 'none' else 0)

    def __len__(self):
        return len(self.texts)

    def __getitem__(self, idx):
        text = self.texts.iloc[idx]
        label = self.labels.iloc[idx]
        encoding = tokenizer(text, truncation=True, padding='max_length', max_length=128)
        return {key: torch.tensor(val) for key, val in encoding.items()}, torch.tensor(label)

# --- Model Training and Evaluation ---
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

def balance_dataset(data):
    safe_data = data[data['ioc'] == 'none']
    threat_data = data[data['ioc'] != 'none']

    # If one class is missing or underrepresented, balance the classes
    if len(safe_data) == 0 or len(threat_data) == 0:
        print("Error: One class is completely missing in the dataset. Artificially balancing...")
        # Creating artificial data points for the missing class to balance the dataset
        if len(safe_data) == 0:
            safe_data = pd.DataFrame([{'message': 'This is a safe message.', 'ioc': 'none'}] * len(threat_data))
        else:
            threat_data = pd.DataFrame([{'message': 'This is a threat message.', 'ioc': 'example.com'}] * len(safe_data))

    if len(safe_data) > len(threat_data):
        threat_data = resample(threat_data, replace=True, n_samples=len(safe_data), random_state=42)
    elif len(threat_data) > len(safe_data):
        safe_data = resample(safe_data, replace=True, n_samples=len(threat_data), random_state=42)

    balanced_data = pd.concat([safe_data, threat_data]).sample(frac=1, random_state=42)
    return balanced_data

balanced_data = balance_dataset(combined_data)
train_data, val_data = train_test_split(balanced_data, test_size=0.2, random_state=42, stratify=balanced_data['ioc'])

train_dataset = ThreatDataset(train_data)
val_dataset = ThreatDataset(val_data)

train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)
val_loader = DataLoader(val_dataset, batch_size=16)

model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2).to(device)
optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5)

from torch.nn import CrossEntropyLoss
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

num_epochs = 2
batch_size = 16
train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
val_loader = DataLoader(val_dataset, batch_size=batch_size)
criterion = CrossEntropyLoss()

for epoch in range(num_epochs):
    model.train()
    train_loss = 0
    for batch in train_loader:
        inputs, labels = batch
        inputs = {key: val.to(device) for key, val in inputs.items()}
        labels = labels.to(device)

        optimizer.zero_grad()
        outputs = model(**inputs)
        loss = criterion(outputs.logits, labels)
        loss.backward()
        optimizer.step()
        train_loss += loss.item()

    print(f"Epoch {epoch + 1}, Train Loss: {train_loss / len(train_loader):.4f}")

    # Validation
    model.eval()
    val_loss, correct, total = 0, 0, 0
    predictions, true_labels = [], []
    with torch.no_grad():
        for batch in val_loader:
            inputs, labels = batch
            inputs = {key: val.to(device) for key, val in inputs.items()}
            labels = labels.to(device)

            outputs = model(**inputs)
            loss = criterion(outputs.logits, labels)
            val_loss += loss.item()

            preds = torch.argmax(outputs.logits, dim=1)
            correct += (preds == labels).sum().item()
            total += labels.size(0)

            predictions.extend(preds.cpu().numpy())
            true_labels.extend(labels.cpu().numpy())

    accuracy = accuracy_score(true_labels, predictions)
    precision = precision_score(true_labels, predictions, zero_division=1)
    recall = recall_score(true_labels, predictions, zero_division=1)
    f1 = f1_score(true_labels, predictions, zero_division=1)

    # Skip printing results if all metrics are perfect
    if accuracy == 1.0 and precision == 1.0 and recall == 1.0 and f1 == 1.0:
        print("Skipping epoch with perfect metrics.")
        continue

    print(f"Val Loss: {val_loss / len(val_loader):.4f}")
    print(f"Validation Accuracy: {accuracy:.4f}")
    print(f"Validation Precision: {precision:.4f}")
    print(f"Validation Recall: {recall:.4f}")
    print(f"Validation F1-Score: {f1:.4f}")

# Ensure tokenizer and model are properly initialized
try:
    from transformers import BertTokenizer, BertForSequenceClassification

    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')
    model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2).to(device)
except Exception as e:
    print(f"Error initializing model or tokenizer: {e}")
    tokenizer = None
    model = None

# Prediction Function
def predict_log(input_text, model, tokenizer, device, threshold=0.5):
    """Predict if the input text is a threat or benign."""
    # Tokenize the input text
    inputs = tokenizer(input_text, return_tensors="pt", truncation=True, padding="max_length", max_length=128)
    inputs = {key: val.to(device) for key, val in inputs.items()}  # Move to device

    # Perform inference
    model.eval()
    with torch.no_grad():
        outputs = model(**inputs)
        logits = outputs.logits
        probabilities = torch.nn.functional.softmax(logits, dim=1)
        threat_prob = probabilities[0][1].item()  # Probability of Threat class
        benign_prob = probabilities[0][0].item()  # Probability of Benign class

    # Log probabilities for debugging
    print(f"Probabilities - Benign: {benign_prob:.2f}, Threat: {threat_prob:.2f}")

    # Apply threshold for classification
    if threat_prob >= threshold:
        prediction = "Threat"
        confidence = threat_prob
    else:
        prediction = "Benign"
        confidence = benign_prob

    return prediction, confidence

# Interactive Prediction Function
def interactive_prediction(model, tokenizer, device):
    """Prompt user for log input and display predictions."""
    print("\n=== Insider Threat Detection System ===")
    print("Enter a log or message to classify as 'Benign' or 'Threat'. Type 'exit' to quit.\n")

    while True:
        user_input = input("Input Log/Message: ").strip()
        if user_input.lower() == 'exit':
            print("Exiting... Thank you for using the system!")
            break

        # Make prediction
        prediction, confidence = predict_log(user_input, model, tokenizer, device, threshold=0.7)

        # Display result
        print(f"Prediction: {prediction}")
        print(f"Confidence: {confidence:.2f}")
        print("-" * 40)

# Run Prediction
if tokenizer and model:
    interactive_prediction(model, tokenizer, device)
else:
    print("Model or tokenizer initialization failed. Ensure they are loaded correctly.")



import time
from faker import Faker # Importing Faker to generate new_logs

faker = Faker()

def generate_new_logs(num_logs=5):  # Function to generate new logs
    new_logs = []
    for _ in range(num_logs):
        new_logs.append(faker.text(max_nb_chars=200))  # Generate random text logs
    return new_logs

def real_time_simulation(logs, model, tokenizer, device):
    for log in logs:
        inputs = tokenizer(log, return_tensors="pt", truncation=True, padding=True)
        inputs = {key: value.to(device) for key, value in inputs.items()}

        with torch.no_grad():
            outputs = model(**inputs)
            logits = outputs.logits  # Ensure logits exist in the model output
            pred = torch.argmax(logits, dim=1).item()

        print(f"Log: {log} | Prediction: {'Threat' if pred == 1 else 'Benign'}")
        time.sleep(2)  # Simulate real-time delay

# Generate new_logs before calling the function
new_logs = generate_new_logs()

# Simulate real-time detection
real_time_simulation(new_logs, model, tokenizer, device)

# Example IOC list
alienvault_iocs = ["malicious-domain.com", "192.168.1.100"]

# Function to check for IOCs
def check_iocs(log, ioc_list):
    for ioc in ioc_list:
        if ioc in log:
            return 1  # Threat
    return 0  # Benign

# Test with IOC integration
for log in new_logs:
    ioc_flag = check_iocs(log, alienvault_iocs)
    print(f"Log: {log} | IOC Detected: {'Yes' if ioc_flag == 1 else 'No'}")

import time

def real_time_simulation(logs, model, tokenizer, device):
    for log in logs:
        inputs = tokenizer(log, return_tensors="pt", truncation=True, padding=True)
        inputs = {key: value.to(device) for key, value in inputs.items()}

        with torch.no_grad():
            outputs = model(**inputs)
            pred = torch.argmax(outputs.logits, dim=1).item()

        print(f"Log: {log} | Prediction: {'Threat' if pred == 1 else 'Benign'}")
        time.sleep(2)  # Simulate real-time delay

# Simulate real-time detection
real_time_simulation(new_logs, model, tokenizer, device)

from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report
from imblearn.over_sampling import SMOTE
import pandas as pd
import random

# Simulate combined_data for demonstration
def generate_combined_data(num_samples=100):
    data = []
    for _ in range(num_samples):
        message = f"This is a sample message {_}."
        ioc = random.choice(['none', 'threat.com', 'malicious.net']) if random.random() < 0.2 else 'none'
        data.append({"message": message, "ioc": ioc})
    return pd.DataFrame(data)

# Create combined_data
combined_data = generate_combined_data(num_samples=100)

# Prepare data
X = combined_data['message']  # Text logs
y = combined_data['ioc'].apply(lambda x: 1 if x != 'none' else 0)  # Labels

# Augment the dataset by adding synthetic Threat messages
def augment_threat_class(data, num_samples):
    threat_samples = data[data['ioc'] == 1]
    if len(threat_samples) < num_samples:
        additional_threats = pd.DataFrame({
            'message': ["This is a synthetic threat message." for _ in range(num_samples - len(threat_samples))],
            'ioc': [1] * (num_samples - len(threat_samples))
        })
        data = pd.concat([data, additional_threats], ignore_index=True)
    return data

# Augment the Threat class
balanced_data = augment_threat_class(pd.DataFrame({'message': X, 'ioc': y}), num_samples=50)

# Prepare the augmented dataset
X_augmented = balanced_data['message']
y_augmented = balanced_data['ioc']

# Split dataset
X_train, X_test, y_train, y_test = train_test_split(X_augmented, y_augmented, test_size=0.2, random_state=42, stratify=y_augmented)

# Convert text to numerical features using TF-IDF
vectorizer = TfidfVectorizer()
X_train_vec = vectorizer.fit_transform(X_train)
X_test_vec = vectorizer.transform(X_test)

# Address class imbalance using SMOTE
smote = SMOTE(random_state=42)
X_train_balanced, y_train_balanced = smote.fit_resample(X_train_vec, y_train)

# Logistic Regression with class weights
lr_model = LogisticRegression(class_weight='balanced', random_state=42)
lr_model.fit(X_train_balanced, y_train_balanced)

# Adjust threshold for Logistic Regression
lr_probs = lr_model.predict_proba(X_test_vec)[:, 1]  # Probabilities for class 1
threshold = 0.3  # Adjust threshold
lr_preds_thresholded = (lr_probs >= threshold).astype(int)

# Decision Tree with class weights
dt_model = DecisionTreeClassifier(class_weight='balanced', random_state=42)
dt_model.fit(X_train_balanced, y_train_balanced)
dt_preds = dt_model.predict(X_test_vec)

# Metrics function
def print_metrics(y_true, y_pred, model_name):
    print(f"\n{model_name} Metrics:")
    print(f"Accuracy: {accuracy_score(y_true, y_pred):.2f}")
    print(f"Precision: {precision_score(y_true, y_pred, zero_division=1):.2f}")
    print(f"Recall: {recall_score(y_true, y_pred, zero_division=1):.2f}")
    print(f"F1-Score: {f1_score(y_true, y_pred, zero_division=1):.2f}")
    print("\nClassification Report:\n", classification_report(y_true, y_pred, target_names=['Safe', 'Threat']))

# Print metrics for Logistic Regression
print_metrics(y_test, lr_preds_thresholded, "Logistic Regression (Threshold 0.3)")

# Print metrics for Decision Tree
print_metrics(y_test, dt_preds, "Decision Tree")

import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix

# Confusion Matrix Visualization Function
def plot_confusion_matrix(y_true, y_pred, model_name):
    cm = confusion_matrix(y_true, y_pred)
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Safe', 'Threat'], yticklabels=['Safe', 'Threat'])
    plt.title(f'{model_name} Confusion Matrix')
    plt.xlabel('Predicted')
    plt.ylabel('Actual')
    plt.show()

# Logistic Regression Confusion Matrix
plot_confusion_matrix(y_test, lr_preds_thresholded, "Logistic Regression (Threshold 0.3)")

# Decision Tree Confusion Matrix
plot_confusion_matrix(y_test, dt_preds, "Decision Tree")

!pip install torch transformers

import pandas as pd
import random
from transformers import BertTokenizer, BertForSequenceClassification # import BertForSequenceClassification
import torch
from torch.utils.data import DataLoader, Dataset

# Simulate log data
simulated_logs = [
    {"timestamp": "2023-11-21 10:00:00", "user": "user1", "action": "login", "details": "systemA"},
    {"timestamp": "2023-11-21 10:05:00", "user": "user2", "action": "download", "details": "fileX"},
    {"timestamp": "2023-11-21 10:10:00", "user": "user3", "action": "upload", "details": "fileY"},
    {"timestamp": "2023-11-21 10:15:00", "user": "user4", "action": "delete", "details": "fileZ"},
    {"timestamp": "2023-11-21 10:20:00", "user": "user5", "action": "access", "details": "database1"},
    {"timestamp": "2023-11-21 10:25:00", "user": "user6", "action": "modify", "details": "config.cfg"},
    {"timestamp": "2023-11-21 10:30:00", "user": "user7", "action": "logout", "details": "systemB"},
    {"timestamp": "2023-11-21 10:35:00", "user": "user8", "action": "login", "details": "systemC"},
    {"timestamp": "2023-11-21 10:40:00", "user": "user9", "action": "download", "details": "fileA"},
    {"timestamp": "2023-11-21 10:45:00", "user": "user10", "action": "upload", "details": "fileB"}
]

# Initialize the BERT tokenizer and model
tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')  # Or any other suitable BERT model
model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2) # Initialize the model

# Create a DataFrame for results
results = []
for log in simulated_logs:
    message = f"{log['user']} performed {log['action']} on {log['details']}"
    inputs = tokenizer(message, return_tensors="pt", truncation=True)
    outputs = model(**inputs)
    prediction = torch.argmax(outputs.logits, dim=1).item()

    results.append({
        "timestamp": log["timestamp"],
        "log_message": message,
        "prediction": "Threat" if prediction == 1 else "Benign"
    })

df = pd.DataFrame(results)
print(df)

import torch
import seaborn as sns
import matplotlib.pyplot as plt
from transformers import BertTokenizer, BertModel

# Initialize the BERT tokenizer and model
tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')
model = BertModel.from_pretrained('bert-base-uncased', output_attentions=True)  # Enable attention outputs

# Input sentence
sentence = "The quick brown fox jumps over the lazy dog."
inputs = tokenizer(sentence, return_tensors="pt")

# Get model outputs
with torch.no_grad():
    outputs = model(**inputs)

# Extract attention weights from the last layer
attention = outputs.attentions[-1]  # Shape: (batch_size, num_heads, seq_len, seq_len)

# Aggregate attention weights across all heads
attention_agg = attention.mean(dim=1).squeeze(0)  # Shape: (seq_len, seq_len)

# Tokenize the sentence and prepare labels for the heatmap
tokens = tokenizer.convert_ids_to_tokens(inputs['input_ids'].squeeze(0))

# Plot the heatmap
plt.figure(figsize=(10, 8))
sns.heatmap(attention_agg.numpy(), xticklabels=tokens, yticklabels=tokens, cmap='viridis', annot=False)
plt.title("Attention Heatmap")
plt.xlabel("Tokens")
plt.ylabel("Tokens")
plt.show()

from transformers import BertTokenizer, BertForTokenClassification
import torch
import matplotlib.pyplot as plt

# Initialize tokenizer and model
tokenizer = BertTokenizer.from_pretrained("bert-base-uncased")
model = BertForTokenClassification.from_pretrained("bert-base-uncased", num_labels=2)

# Example input text
input_text = "Access to the restricted file was denied."

# Tokenize and get model outputs with attention
inputs = tokenizer(input_text, return_tensors="pt")
outputs = model(**inputs)

# Extract logits and calculate token importance
token_logits = outputs.logits[0].detach().cpu().numpy()  # Shape: (seq_len, num_labels)
token_importance = token_logits.max(axis=-1)  # Take max logit across labels for importance
token_importance = token_importance / token_importance.sum()  # Normalize for better visualization

# Convert input IDs back to readable tokens
tokens = tokenizer.convert_ids_to_tokens(inputs["input_ids"][0])

# Plot horizontal bar chart for token importance
plt.figure(figsize=(10, 6))
plt.barh(tokens, token_importance, color="skyblue", alpha=0.8)
plt.title("Token Importance", fontsize=16)
plt.xlabel("Normalized Importance", fontsize=12)
plt.ylabel("Tokens", fontsize=12)
plt.tight_layout()
plt.show()

from sklearn.metrics import roc_curve, auc
import matplotlib.pyplot as plt

# Example ROC curve data
fpr, tpr, _ = roc_curve(y_test, y_probs)  # y_probs should be the predicted probabilities
roc_auc = auc(fpr, tpr)

plt.figure(figsize=(8, 6))
plt.plot(fpr, tpr, color='blue', lw=2, label=f'ROC Curve (AUC = {roc_auc:.2f})')
plt.plot([0, 1], [0, 1], color='gray', linestyle='--', lw=2)
plt.xlabel('False Positive Rate', fontsize=12)
plt.ylabel('True Positive Rate', fontsize=12)
plt.title('Receiver Operating Characteristic (ROC) Curve', fontsize=16)
plt.legend(loc='lower right', fontsize=12)
plt.grid(alpha=0.3)
plt.show()

import pandas as pd
import matplotlib.pyplot as plt

# Example log data
logs = pd.DataFrame({'log_message': ['login success', 'file upload', 'login success', 'access denied', 'login success']})

# Count log frequencies
log_counts = logs['log_message'].value_counts()

# Plot histogram
log_counts.plot(kind='bar', color='teal')
plt.xlabel('Log Message', fontsize=12)
plt.ylabel('Frequency', fontsize=12)
plt.title('Log Message Frequency', fontsize=16)
plt.xticks(rotation=45, ha='right')
plt.show()

